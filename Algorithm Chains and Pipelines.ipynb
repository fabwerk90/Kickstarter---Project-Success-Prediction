{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Chains and Pipelines\n",
    "* chaining together many different processing steps and ML models\n",
    "* Pipeline class and GridSearchCV to search over paramters for all processing steps at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages:\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and split the data:\n",
    "cancer = load_breast_cancer() #as sklearn.utils.Bunch\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute minimum and maximum of the training data\n",
    "scaler = MinMaxScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescale the training data\n",
    "X_train_scaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score 0.97\n"
     ]
    }
   ],
   "source": [
    "#learn an SVM on the scaled training data:\n",
    "svm = SVC()\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "# scale the test data and score the scaled data:\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(\"Test score {:.2f}\".format(svm.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* we want to find better parameters for SVC using GridSearchCV\n",
    "* **Following shows a naive approach (only for illustration purpose):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cv accuracy: 0.97\n",
      "Best set score: 0.97\n",
      "Best parameters:  {'C': 10, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "             'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, cv=5) #cv=5: 5-fold cross validation\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "print('Best cv accuracy: {:.2f}'.format(grid.best_score_))\n",
    "print('Best set score: {:.2f}'.format(grid.score(X_test_scaled, y_test)))\n",
    "print('Best parameters: ', grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem of the approach:\n",
    "* for each split in CV, some of the original training set will be declared as training data of the split and some as the test data of the split\n",
    "* Test part will is used to measure what new data will look like to a model trained on the training part. \n",
    "* **By scaling the data we already used some information in the test part of the split** (find the right scaling for the complete training data)\n",
    "* Splits in the CV no longer reflect how new data will look to the modelling process\n",
    "* **This leads to overly optemistic results and parameters will may selected suboptimal**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "* splitting of the data set (CV) should be done before doing any preprocessing\n",
    "* **Pipeline class: allows gluinig multiple processing steps into a single sk-learn estimator\n",
    "* Most common use: chaining preprocessing steps (like scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()), ('svm', SVC())])\n",
    "#Pipeline with 2 steps: first scaling (minmax), than svm as instance of SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score 0.97\n"
     ]
    }
   ],
   "source": [
    "#fit the pipeline like any other estimtor:\n",
    "pipe.fit(X_train, y_train)\n",
    "#1st calls fit on the first step(scaler) -> transforming the data\n",
    "#2nd fits the SVM with the scaled data\n",
    "print('Test score {:.2f}'.format(pipe.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* score method on pipe: \n",
    "    * 1st transforms the test data using scaler\n",
    "    * 2nd class the score method on the SVM using the scaled test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pipelines in Grid Searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Slight change to the usual approach:\n",
    "    * We need to specify for each paramter which step of the pipeline it belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'svm__C': [0.001, 0.01, 0.1, 1, 10, 100], 'svm__gamma': [0.001, 0.01, 0.1, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation accuracy: 0.97\n",
      "Test set score: 0.97\n",
      "Best parameters: {'svm__C': 10, 'svm__gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "# Now we can use GridSearchCV as normal:\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5) \n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_)) \n",
    "print(\"Test set score: {:.2f}\".format(grid.score(X_test, y_test))) \n",
    "print(\"Best parameters: {}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Estimating the scale of the data using the test fold usually does not have a terrible impact, while using the test fold in feature extraction and feature selection can lead to substantial differences in outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
